[
  {
    "objectID": "code-of-conduct.html",
    "href": "code-of-conduct.html",
    "title": "Code of conduct",
    "section": "",
    "text": "We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.\nWe pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community."
  },
  {
    "objectID": "code-of-conduct.html#our-standards",
    "href": "code-of-conduct.html#our-standards",
    "title": "Code of conduct",
    "section": "Our standards",
    "text": "Our standards\nExamples of behavior that contributes to a positive environment for our community include:\n\nDemonstrating empathy and kindness toward other people\nBeing respectful of differing opinions, viewpoints, and experiences\nGiving and gracefully accepting constructive feedback\nAccepting responsibility and apologizing to those affected by our mistakes, and learning from the experience\nFocusing on what is best not just for us as individuals, but for the overall community\n\nExamples of unacceptable behavior include:\n\nThe use of sexualized language or imagery, and sexual attention or advances of any kind\nTrolling, insulting or derogatory comments, and personal or political attacks\nPublic or private harassment\nPublishing others’ private information, such as a physical or email address, without their explicit permission\nOther conduct which could reasonably be considered inappropriate in a professional setting"
  },
  {
    "objectID": "code-of-conduct.html#enforcement-responsibilities",
    "href": "code-of-conduct.html#enforcement-responsibilities",
    "title": "Code of conduct",
    "section": "Enforcement responsibilities",
    "text": "Enforcement responsibilities\nCommunity leaders, including but not limited to the editorial board and associate editors, are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.\nCommunity leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate."
  },
  {
    "objectID": "code-of-conduct.html#scope",
    "href": "code-of-conduct.html#scope",
    "title": "Code of conduct",
    "section": "Scope",
    "text": "Scope\nThis Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, acting as an appointed representative at an online or offline event, or posting public reviews, issues, or comments on submissions."
  },
  {
    "objectID": "code-of-conduct.html#enforcement",
    "href": "code-of-conduct.html#enforcement",
    "title": "Code of conduct",
    "section": "Enforcement",
    "text": "Enforcement\nInstances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement at the JoVI Code of Conduct Incident Report Form. All complaints will be reviewed and investigated promptly and fairly.\nAll community leaders are obligated to respect the privacy and security of the reporter of any incident."
  },
  {
    "objectID": "code-of-conduct.html#enforcement-guidelines",
    "href": "code-of-conduct.html#enforcement-guidelines",
    "title": "Code of conduct",
    "section": "Enforcement guidelines",
    "text": "Enforcement guidelines\nCommunity leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:\n\nCorrection\n\nCommunity Impact\nUse of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.\n\n\nConsequence\nA private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested. Editors may require that the language of a review or response be changed before allowing the message to proceed to other parties.\n\n\n\nWarning\n\nCommunity Impact\nA violation through a single incident or series of actions.\n\n\nConsequence\nA warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interactions in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.\n\n\n\nTemporary ban\n\nCommunity Impact\nA serious violation of community standards, including sustained inappropriate behavior.\n\n\nConsequence\nA temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.\n\n\n\nPermanent ban\n\nCommunity Impact\nDemonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.\n\n\nConsequence\nA permanent ban from any sort of public interaction within the community."
  },
  {
    "objectID": "code-of-conduct.html#attribution",
    "href": "code-of-conduct.html#attribution",
    "title": "Code of conduct",
    "section": "Attribution",
    "text": "Attribution\nThis Code of Conduct is adapted from the Contributor Covenant, version 2.0.\nCommunity Impact Guidelines were inspired by Mozilla’s code of conduct enforcement ladder.\nFor answers to common questions about the Contributor Covenant, see the FAQ. Translations are available here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The Journal of Visualization and Interaction",
    "section": "",
    "text": "The Journal of Visualization and Interaction (JoVI) is a venue for publishing scholarly work related to the fields of visualization and human-computer interaction. Contributions to the journal include research in:\n\nhow people understand and interact with information and technology,\ninnovations in interaction techniques, interactive systems, or tools,\nsystematic literature reviews, and\nreplication studies\ncomments on existing publications.\n\nCross-disciplinary work from other fields such as statistics or psychology, which is relevant to the fields of visualization or human-computer interaction is also welcome.\nJoVI’s missions are the following:"
  },
  {
    "objectID": "index.html#open",
    "href": "index.html#open",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open by default",
    "text": "Open by default\nJoVI strongly supports transparency and openness and implements it as a default to enable readers to scrutinize and build on the research. All published manuscripts are open access. For any empirical components, manuscripts must make all raw data and material essential for replication available for public scrutiny. For any computational components, all codes need to be reproducible within a reasonable effort. When ethical concerns prevent submissions to meet these requirements, the manuscript must clearly describe the characteristics of these artifacts and adequately justify the tradeoff between openness and ethics."
  },
  {
    "objectID": "index.html#open-review",
    "href": "index.html#open-review",
    "title": "The Journal of Visualization and Interaction",
    "section": "Open review, comments, and continued conversation",
    "text": "Open review, comments, and continued conversation\nAll submitted work, reviews, and discussions will by default be publicly available for other researchers to use. To encourage accountability, editors’ names are listed on the articles they accept, and reviewers may choose to be named or anonymous. All submissions and their accompanying reviews and discussions remain accessible whether or not an article is accepted. To foster discussions that go beyond the initial reviewer/author exchanges, we welcome post-publication commentaries on articles."
  },
  {
    "objectID": "index.html#knowledge",
    "href": "index.html#knowledge",
    "title": "The Journal of Visualization and Interaction",
    "section": "Knowledge over novelty",
    "text": "Knowledge over novelty\nWe prioritize how research advances knowledge rather than superficial novelty. Reviews aim to evaluate the credibility of a manuscript’s claims and the clarity of its evidence. Contributions of interaction techniques or interactive systems may meet this knowledge criterion through existence proofs. For empirical works, JoVI encourages registered reports—the reviewing of study plans prior to execution—and has a process to support this type of contribution. The discourses on the merit of the manuscripts must be justified by evidence, credible literature, or cogent argument."
  },
  {
    "objectID": "index.html#humane",
    "href": "index.html#humane",
    "title": "The Journal of Visualization and Interaction",
    "section": "A more humane process, respectful of everyone’s time",
    "text": "A more humane process, respectful of everyone’s time\nJoVI respects the time and effort of both authors and reviewers, and aims for a collaborative, humane review process. To that end, JoVI does not publish a limited number of manuscripts and does not seek to have a certain rejection rate. Instead, review proceeds as a back and forth between authors and reviewers, with the goal of improving the work. Authors can expect that their submissions will not be rejected over easily fixable technicalities."
  },
  {
    "objectID": "index.html#ambitions",
    "href": "index.html#ambitions",
    "title": "The Journal of Visualization and Interaction",
    "section": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents",
    "text": "Ambitions: Experimental track for new article formats, review processes, and articles as living documents\nIn addition to the missions above, JoVI also aspires to be a platform for other improvements of scholarly communication. On an alternate, optional submission track, we will continually experiment with new article formats (including modern, interactive formats), new review processes, and articles as living documents. This experimentation will be motivated by re-conceptualizing peer review as a humane, constructive process aimed at improving work rather than gatekeeping."
  },
  {
    "objectID": "organizers.html",
    "href": "organizers.html",
    "title": "Organizers",
    "section": "",
    "text": "Lonni Besançon, Monash University\nFlorian Echtler, Aalborg University\nMatthew Kay, Northwestern University\nChat Wacharamanotham, Swansea University\n\nJoVI also owes a huge debt to Steve Haroz, who was instrumental in its formation and early iterations."
  },
  {
    "objectID": "structured-abstract-examples.html",
    "href": "structured-abstract-examples.html",
    "title": "Examples of structured abstracts",
    "section": "",
    "text": "Below are several examples of structured abstracts written based on existing papers in order to demonstrate their use.\nSee the top of the JoVI article template for the structured abstract template."
  },
  {
    "objectID": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "href": "structured-abstract-examples.html#perceptual-proxies-empirical",
    "title": "Examples of structured abstracts",
    "section": "Perceptual proxies (empirical)",
    "text": "Perceptual proxies (empirical)\nBased on Perceptual proxies for extracting averages in data visualization\n\nIntroduction\nAcross science, education, and business, we process and communicate data visually. One bedrock finding in data visualization research is a hierarchy of precision for perceptual encodings of data, e.g., that encoding data with Cartesian positions allows more precise comparisons than encoding with sizes. But this hierarchy has only been tested for single value comparisons, under the assumption that those lessons would extrapolate to multi-value comparisons.\n\n\nData Collection or Source\nWe ran four within-subject behavioral experiments (three preregistered) to measure subjects’ ability to differentiate single values or set averages. The experiments used a staircase method to measure accuracy when comparing pairs of dot plots (position), floating bar graphs (length), or regular bar graphs (position + length).\n\n\nData Analysis\nWe used the stopping point of the staircase to estimate the just noticeable difference and ran within-subject anovas and t-test to estimate differences between (1) chart types, (2) single values vs. set averages, and (3) set sizes.\n\n\nAnalysis Results\nResults include: (1) Confirming known findings in the visualization literature, the results showed that single-value comparison was least precise with floating bar graphs (length only). (2) However, when comparing averages across multiple data points, the discriminability was indistinguishable between chart types. (3) An exploratory analysis found that comparisons between different set sizes reduced accuracy but not reliably for all chart types.\n\n\nConclusion\nViewers compare values using surprisingly primitive perceptual cues, e.g., the summed area of bars in a bar graph. These results highlight a critical need to study a broader constellation of visual cues that mediate the patterns that we can see in data, across visualization types and tasks.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "href": "structured-abstract-examples.html#open-practices-in-vis-empirical",
    "title": "Examples of structured abstracts",
    "section": "Open practices in vis (empirical)",
    "text": "Open practices in vis (empirical)\nBased on Open practices in visualization research\n\nIntroduction\nTwo fundamental tenets of scientific research are that it can be scrutinized and built-upon. Both require that the collected data and supporting materials be shared, so others can examine, reuse, and extend them. Assessing the accessibility of these components and the paper itself can serve as a proxy for the reliability, replicability, and applicability of a field’s research.\n\n\nData Collection or Source\nI checked all papers published in VIS in 2017 to see which were available on a preprint repository, included a preregistration, included data collection materials, included raw data, or included computation/analysis materials.\n\n\nData Analysis\nIn an exploratory analysis of all VIS publications in 2017, I calculated the proportion of papers with a preprint and open practices on a reliable open access repository or a website without long-term availability.\n\n\nAnalysis Results\nA minority of published articles are available on an open access server, and extremely few included additional research materials on an open and reliable repository. The availability also varied by conference track.\n\n\nConclusion\nThe lack of open practices may severely hamper the ability to scrutinize, replicate, or reproduce visualization research. The paper provides suggestions for authors, reviewers, and editors to improve the poor state of open practices in the field.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "structured-abstract-examples.html#explorable-multiverse-technique",
    "href": "structured-abstract-examples.html#explorable-multiverse-technique",
    "title": "Examples of structured abstracts",
    "section": "Explorable multiverse (technique)",
    "text": "Explorable multiverse (technique)\nBased on Increasing the Transparency of Research Papers with Explorable Multiverse Analyses\n\nIntroduction\nWe present explorable multiverse analysis reports (EMARs), a new approach to statistical reporting where readers of research papers can explore alternative analysis options by interacting with the paper itself. This approach draws from two ideas: multiverse analysis, a philosophy of statistical reporting where paper authors report the outcomes of many different statistical analyses in order to show how fragile or robust their findings are; and explorable explanations, narratives that can be read as normal explanations but where the reader can also become active by dynamically changing some elements of the explanation.\n\n\nImplementation\nWe use R scripts to build EMARs by pre-computing analysis results from every universe from a combination of all analysis parameters in a given multiverse. The output from those scripts is then presented using interactive HTML+JavaScript templates.\n\n\nDemonstration\nWe prototype five example EMARs by re-analyzing existing papers and building interactive papers to demonstrate different interactive approaches to communicating multiverses. We show how combining multiverse analysis and explorable explanations might complement existing reporting approaches and constitute a step towards more transparent research papers.\nBased on these examples and existing literature on multiverse analysis, we develop a design space for multiverse analysis reports. Our design space describes analysis parameters, analysis options, and multiplexing and aggregation techniques for summarizing and communicating multiverses. We identify several challenges to multiverse construction, including identifying simple end goals that can be multiplexed across universes (which can be easier with single statistics than entire plots, for example), and provide recommendations for writing conclusions in papers that span multiverses (to avoid authors/readers simply selecting desired results).\n\n\nConclusion\nThe development of tools to facilitate the multiverse analysis process within analysts’ workflows remains a substantial challenge: our prototypes consist of custom R scripts and HTML templates that require significant technical expertise to develop. Automating these workflows for data analysts is an important next step.\n\n\nMaterials\nSee live demo here. [NOTE: for JoVI, a backup link to a permanent repository should also be included with live demo links]"
  },
  {
    "objectID": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "href": "structured-abstract-examples.html#binaryswipes-technique-user-study",
    "title": "Examples of structured abstracts",
    "section": "BinarySwipes (technique + user study)",
    "text": "BinarySwipes (technique + user study)\nBased on BinarySwipes: Fast List Search on Small Touchscreens (straightforward UI technique & user study) [Florian]\n\nIntroduction\nWe present BinarySwipes, an interaction technique based on binary search which is designed to speed up list search tasks on space-constrained touchscreens.\nSmartwatches and other wearables generally have small screens, thereby complicating touch-based interaction. Selection from a long list, eg to locate a contact or a music track, is particularly cumbersome due to the limited interaction space.\n\n\nImplementation\nTBD\n\n\nDemonstration\nTBD\n\n\nData Collection or Source\nWe evaluate a prototypical implementation of BinarySwipes on a smartwatch with 21 participants in a controlled user study. We measure task completion time, error rate, and self-reported NASA TLX values.\n\n\nData Analysis\nWe analyze our data with respect to normal distribution (Shapiro-Wilk) and statistically significant differences between conditions (ANOVA with post-hoc Tukey HSD, Bonferroni correction).\n\n\nAnalysis Results\nResults from our evaluation show improved performance over a plain linear search on lists with 100, 200 and 500 entries, but also increased mental load on the users.\n\n\nConclusion\nBinarySwipes is a viable technique for quickly locating known items in long lists, but challenges remain for exploratory search, or when the presence of the item is not known in advance.\n\n\nMaterials\nTBD"
  },
  {
    "objectID": "submit.html",
    "href": "submit.html",
    "title": "How to submit to JoVI",
    "section": "",
    "text": "JoVI has two submission tracks: the traditional track and the experimental (“Github”) track."
  },
  {
    "objectID": "submit.html#traditional",
    "href": "submit.html#traditional",
    "title": "How to submit to JoVI",
    "section": "Traditional track",
    "text": "Traditional track\nSubmission for the traditional track proceeds via the OJS submission system, hosted courtesy of the Aalborg University Library. Please create an OJS account, preferably using your default institutional email address, and follow the instructions on OJS to submit your paper and supplementary materials."
  },
  {
    "objectID": "submit.html#experimental",
    "href": "submit.html#experimental",
    "title": "How to submit to JoVI",
    "section": "Experimental (“Github”) track",
    "text": "Experimental (“Github”) track\nThe experimental track is an alternative submission and review process that manifests our commitment to experimenting with review processes. This track is less well-defined, in part because we wish it to evolve with authors as we use it.\nAll papers in the “Github” track must be written in Quarto, a markdown-based computational notebook format. Quarto can be used with documents written in a variety of forms (RMarkdown, Jupyter notebook, Word, Latex), and supports embedded computation (in mayn languages, including R, python, and Julia) and interactivity (using JavaScript / Observable).\nAll review on the experimental track will proceed as Github issues and pull requests, and published papers on this track can be updated using pull requests, even after publication.\nTo submit to the experimental track, write your paper in quarto using this template and then submit your article INSERT INSTRUTIONS."
  }
]